{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731d1c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dartfs-hpc/rc/home/d/f0036rd/.conda/envs/SHAPenv/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "2022-07-07 23:22:56.867400: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-07 23:22:56.868458: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-07 23:22:56.876496: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "class ShapNN(object):\n",
    "    \n",
    "    def __init__(self, mode, hidden_units=[100], learning_rate=0.001, \n",
    "                 dropout = 0., activation=None, initializer=None,\n",
    "                 weight_decay=0.0001, optimizer='adam', batch_size=128,\n",
    "                 warm_start=False, max_epochs=100, validation_fraction=0.1,\n",
    "                 early_stopping=0, address=None, test_batch_size=1000,\n",
    "                 random_seed=666):\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.batch_size = batch_size\n",
    "        self.test_batch_size = test_batch_size\n",
    "        self.hidden_units = hidden_units\n",
    "        self.initializer = initializer\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.weight_decay = weight_decay\n",
    "        self.optimizer = optimizer\n",
    "        self.learning_rate = learning_rate\n",
    "        self.warm_start = warm_start\n",
    "        self.max_epochs = max_epochs\n",
    "        self.early_stopping = early_stopping\n",
    "        self.validation_fraction = validation_fraction\n",
    "        self.address = address\n",
    "        self._extra_train_ops = []\n",
    "        self.random_seed = random_seed\n",
    "        self.is_built = False\n",
    "\n",
    "    def prediction_cost(self, X_test, y_test, batch_size=None):\n",
    "        \n",
    "        if batch_size is None:\n",
    "            batch_size = self.test_batch_size\n",
    "        assert len(set(y_test)) == self.num_classes, 'Number of classes does not match!'\n",
    "        with self.graph.as_default():\n",
    "            losses = []\n",
    "            idxs = np.arange(len(X_test))            \n",
    "            batches = [idxs[k * batch_size: (k+1) * batch_size] \n",
    "                       for k in range(int(np.ceil(len(idxs)/batch_size)))]\n",
    "            for batch in batches:\n",
    "                losses.append(self.sess.run(self.prediction_loss, {self.input_ph:X_test[batch],\n",
    "                                                                   self.labels:y_test[batch]}))\n",
    "            return np.mean(losses)     \n",
    "        \n",
    "    def score(self, X_test, y_test, batch_size=None):\n",
    "        \n",
    "        if batch_size is None:\n",
    "            batch_size = self.test_batch_size\n",
    "        assert len(set(y_test)) == self.num_classes, 'Number of classes does not match!'\n",
    "        with self.graph.as_default():\n",
    "            scores = []\n",
    "            idxs = np.arange(len(X_test))     \n",
    "            batches = [idxs[k * batch_size: (k+1) * batch_size] \n",
    "                       for k in range(int(np.ceil(len(idxs)/batch_size)))]\n",
    "            for batch in batches:\n",
    "                scores.append(self.sess.run(self.prediction_score, {self.input_ph:X_test[batch],\n",
    "                                                                   self.labels:y_test[batch]}))\n",
    "            return np.mean(scores)\n",
    "        \n",
    "    def predict_proba(self, X_test, batch_size=None):\n",
    "        \n",
    "        if batch_size is None:\n",
    "            batch_size = self.test_batch_size\n",
    "        with self.graph.as_default():\n",
    "            probs = []\n",
    "            idxs = np.arange(len(X_test))     \n",
    "            batches = [idxs[k * batch_size: (k+1) * batch_size] \n",
    "                       for k in range(int(np.ceil(len(idxs)/batch_size)))]\n",
    "            for batch in batches:\n",
    "                probs.append(self.sess.run(self.probs, {self.input_ph:X_test[batch]}))\n",
    "            return np.concatenate(probs, axis=0)    \n",
    "        \n",
    "    def predict_log_proba(self, X_test, batch_size=None):\n",
    "        \n",
    "        if batch_size is None:\n",
    "            batch_size = self.test_batch_size\n",
    "        with self.graph.as_default():\n",
    "            probs = []\n",
    "            idxs = np.arange(len(X_test))            \n",
    "            batches = [idxs[k * batch_size: (k+1) * batch_size] \n",
    "                       for k in range(int(np.ceil(len(idxs)/batch_size)))]\n",
    "            for batch in batches:\n",
    "                probs.append(self.sess.run(self.probs, {self.input_ph:X_test[batch]}))\n",
    "            return np.log(np.clip(np.concatenate(probs), 1e-12, None))   \n",
    "        \n",
    "    def cost(self, X_test, y_test, batch_size=None):\n",
    "        \n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        with self.graph.as_default():\n",
    "            losss = []\n",
    "            idxs = np.arange(len(X_test))            \n",
    "            batches = [idxs[k * batch_size: (k+1) * batch_size] \n",
    "                       for k in range(int(np.ceil(len(idxs)/batch_size)))]\n",
    "            for batch in batches:\n",
    "                losss.append(self.sess.run(self.prediction_loss, {self.input_ph:X_test[batch],\n",
    "                                                                   self.labels:y_test[batch]}))\n",
    "            return np.mean(losss)\n",
    "    \n",
    "    def predict(self, X_test, batch_size=None):\n",
    "        \n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        with self.graph.as_default():\n",
    "            predictions = []\n",
    "            idxs = np.arange(len(X_test))\n",
    "            batches = [idxs[k * batch_size: (k+1) * batch_size] \n",
    "                       for k in range(int(np.ceil(len(idxs)/batch_size)))]\n",
    "            for batch in batches:\n",
    "                predictions.append(self.sess.run(self.predictions, {self.input_ph:X_test[batch]}))\n",
    "            return np.concatenate(predictions)\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None, sources=None, max_epochs=None,\n",
    "            batch_size=None, save=False, load=False, sample_weight=None,\n",
    "            metric='accuracy'):\n",
    "        \n",
    "        self.num_classes = len(set(y))\n",
    "        self.metric = metric\n",
    "        if max_epochs is None:\n",
    "            max_epochs = self.max_epochs\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        if not self.is_built:\n",
    "            self.graph = tf.Graph() \n",
    "            with self.graph.as_default():\n",
    "                config = tf.ConfigProto()\n",
    "                config.gpu_options.allow_growth=True\n",
    "                self.sess = tf.Session(config=config)\n",
    "        with self.graph.as_default():\n",
    "            tf.set_random_seed(self.random_seed)\n",
    "            try:\n",
    "                self.global_step = tf.train.create_global_step()\n",
    "            except ValueError:\n",
    "                self.global_step = tf.train.get_global_step()\n",
    "            if not self.is_built:\n",
    "                self._build_model(X, y)\n",
    "                self.saver = tf.train.Saver()\n",
    "            self._initialize()\n",
    "            if len(X):\n",
    "                if X_val is None and self.validation_fraction * len(X) > 2:\n",
    "                    X_train, X_val, y_train, y_val, sample_weight, _ = train_test_split(\n",
    "                        X, y, sample_weight, test_size=self.validation_fraction)\n",
    "                else:\n",
    "                    X_train, y_train = X, y\n",
    "                self._train_model(X_train, y_train, X_val=X_val, y_val=y_val,\n",
    "                                  max_epochs=max_epochs, batch_size=batch_size,\n",
    "                                  sources=sources, sample_weight=sample_weight)\n",
    "                if save and self.address is not None:\n",
    "                    self.saver.save(self.sess, self.address)\n",
    "            \n",
    "    def _train_model(self, X, y, X_val, y_val, max_epochs, batch_size, \n",
    "                     sources=None, sample_weight=None):\n",
    "        \n",
    "        \n",
    "        assert len(X)==len(y), 'Input and labels not the same size'\n",
    "        self.history = {'metrics':[], 'idxs':[]}\n",
    "        stop_counter = 0\n",
    "        best_performance = None\n",
    "        for epoch in range(max_epochs):\n",
    "            vals_metrics, idxs = self._one_epoch(\n",
    "                X, y, X_val, y_val, batch_size, sources=sources, sample_weight=sample_weight)\n",
    "            self.history['idxs'].append(idxs)\n",
    "            self.history['metrics'].append(vals_metrics)\n",
    "            if self.early_stopping and X_val is not None:\n",
    "                current_performance = np.mean(val_acc)\n",
    "                if best_performance is None:\n",
    "                    best_performance = current_performance\n",
    "                if current_performance > best_performance:\n",
    "                    best_performance = current_performance\n",
    "                    stop_counter = 0\n",
    "                else:\n",
    "                    stop_counter += 1\n",
    "                    if stop_counter > self.early_stopping:\n",
    "                        break\n",
    "        \n",
    "    def _one_epoch(self, X, y, X_val, y_val, batch_size, sources=None, sample_weight=None):\n",
    "        \n",
    "        vals = []\n",
    "        if sources is None:\n",
    "            if sample_weight is None:\n",
    "                idxs = np.random.permutation(len(X))\n",
    "            else:\n",
    "                idxs = np.random.choice(len(X), len(X), p=sample_weight/np.sum(sample_weight))    \n",
    "            batches = [idxs[k*batch_size:(k+1) * batch_size]\n",
    "                       for k in range(int(np.ceil(len(idxs)/batch_size)))]\n",
    "            idxs = batches\n",
    "        else:\n",
    "            idxs = np.random.permutation(len(sources.keys()))\n",
    "            batches = [sources[i] for i in idxs]\n",
    "        for batch_counter, batch in enumerate(batches):\n",
    "            self.sess.run(self.train_op, \n",
    "                          {self.input_ph:X[batch], self.labels:y[batch],\n",
    "                           self.dropout_ph:self.dropout})\n",
    "            if X_val is not None:\n",
    "                if self.metric=='accuracy':\n",
    "                    vals.append(self.score(X_val, y_val))\n",
    "                elif self.metric=='f1':\n",
    "                    vals.append(f1_score(y_val, self.predict(X_val)))\n",
    "                elif self.metric=='auc':\n",
    "                    vals.append(roc_auc_score(y_val, self.predict_proba(X_val)[:,1]))\n",
    "                elif self.metric=='xe':\n",
    "                    vals.append(-self.prediction_cost(X_val, y_val))\n",
    "        return np.array(vals), np.array(idxs)\n",
    "    \n",
    "    def _initialize(self):\n",
    "        \n",
    "        uninitialized_vars = []\n",
    "        if self.warm_start:\n",
    "            for var in tf.global_variables():\n",
    "                try:\n",
    "                    self.sess.run(var)\n",
    "                except tf.errors.FailedPreconditionError:\n",
    "                    uninitialized_vars.append(var)\n",
    "        else:\n",
    "            uninitialized_vars = tf.global_variables()\n",
    "        self.sess.run(tf.initializers.variables(uninitialized_vars))\n",
    "        \n",
    "    def _build_model(self, X, y):\n",
    "        \n",
    "        self.num_classes = len(set(y))\n",
    "        if self.initializer is None:\n",
    "            initializer = tf.initializers.variance_scaling(distribution='uniform')\n",
    "        if self.activation is None:\n",
    "            activation = lambda x: tf.nn.relu(x)\n",
    "        self.input_ph = tf.placeholder(dtype=tf.float32, shape=(None,) + X.shape[1:], name='input')\n",
    "        self.dropout_ph = tf.placeholder_with_default(\n",
    "            tf.constant(0., dtype=tf.float32), shape=(), name='dropout')\n",
    "        if self.mode=='regression':\n",
    "            self.labels = tf.placeholder(dtype=tf.float32, shape=(None, ), name='label')\n",
    "        else:\n",
    "            self.labels = tf.placeholder(dtype=tf.int32, shape=(None, ), name='label')\n",
    "        x = tf.reshape(self.input_ph, shape=(-1, np.prod(X.shape[1:])))\n",
    "        for layer, hidden_unit in enumerate(self.hidden_units):\n",
    "            with tf.variable_scope('dense_{}'.format(layer)):\n",
    "                x = self._dense(x, hidden_unit, dropout=self.dropout_ph, \n",
    "                           initializer=self.initializer, activation=activation)\n",
    "        with tf.variable_scope('final'):\n",
    "            self.prelogits = x\n",
    "            self._final_layer(self.prelogits, self.num_classes, self.mode)\n",
    "        self._build_train_op()\n",
    "        \n",
    "    def _build_train_op(self):\n",
    "        \n",
    "        \"\"\"Build taining specific ops for the graph.\"\"\"\n",
    "        learning_rate = tf.constant(self.learning_rate, tf.float32) ##fixit\n",
    "        trainable_variables = tf.trainable_variables()\n",
    "        grads = tf.gradients(self.loss, trainable_variables)\n",
    "        self.grad_flat = tf.concat([tf.reshape(grad, (-1, 1)) for grad in grads], axis=0)\n",
    "        if self.optimizer == 'sgd':\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        elif self.optimizer == 'mom':\n",
    "            optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "        elif self.optimizer == 'adam':\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        apply_op = optimizer.apply_gradients(\n",
    "            zip(grads, trainable_variables),\n",
    "            global_step=self.global_step, name='train_step')\n",
    "        train_ops = [apply_op] + self._extra_train_ops + tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        previous_ops = [tf.group(*train_ops)]\n",
    "        with tf.control_dependencies(previous_ops):\n",
    "            self.train_op = tf.no_op(name='train')   \n",
    "        self.is_built = True\n",
    "    \n",
    "    def _final_layer(self, x, num_classes, mode):\n",
    "        \n",
    "        if mode=='regression':\n",
    "            self.logits = self._dense(x, 1, dropout=self.dropout_ph)\n",
    "            self.predictions = tf.reduce_sum(self.logits, axis=-1)\n",
    "            regression_loss = tf.nn.l2_loss(self.predictions - self.labels) ##FIXIT\n",
    "            self.prediction_loss = tf.reduce_mean(regression_loss, name='l2')\n",
    "            residuals = self.predictions - self.labels\n",
    "            var_predicted = tf.reduce_mean(residuals**2) - tf.reduce_mean(residuals)**2\n",
    "            var_labels = tf.reduce_mean(self.labels**2) - tf.reduce_mean(self.labels)**2\n",
    "            self.prediction_score = 1 - var_predicted/(var_labels + 1e-12)\n",
    "        else:\n",
    "            self.logits = self._dense(x, num_classes, dropout=self.dropout_ph)\n",
    "            self.probs = tf.nn.softmax(self.logits)\n",
    "            xent_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits=self.logits, labels=tf.cast(self.labels, tf.int32))\n",
    "            self.prediction_loss = tf.reduce_mean(xent_loss, name='xent')\n",
    "            self.predictions = tf.argmax(self.probs, axis=-1, output_type=tf.int32)\n",
    "            correct_predictions = tf.equal(self.predictions, self.labels)\n",
    "            self.prediction_score = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "        self.loss = self.prediction_loss + self._reg_loss()\n",
    "                \n",
    "    def _dense(self, x, out_dim, dropout=tf.constant(0.), initializer=None, activation=None):\n",
    "        \n",
    "        if initializer is None:\n",
    "            initializer = tf.initializers.variance_scaling(distribution='uniform')\n",
    "        w = tf.get_variable('DW', [x.get_shape()[1], out_dim], initializer=initializer)\n",
    "        b = tf.get_variable('Db', [out_dim], initializer=tf.constant_initializer())\n",
    "        x = tf.nn.dropout(x, 1. - dropout)\n",
    "        if activation:\n",
    "            x = activation(x)\n",
    "        return tf.nn.xw_plus_b(x, w, b)\n",
    "    \n",
    "    def _reg_loss(self, order=2):\n",
    "        \"\"\"Regularization loss for weight decay.\"\"\"\n",
    "        losss = []\n",
    "        for var in tf.trainable_variables():\n",
    "            if var.op.name.find(r'DW') > 0 or var.op.name.find(r'CW') > 0: ##FIXIT\n",
    "                if order==2:\n",
    "                    losss.append(tf.nn.l2_loss(var))\n",
    "                elif order==1:\n",
    "                    losss.append(tf.abs(var))\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid regularization order!\")\n",
    "        return tf.multiply(self.weight_decay, tf.add_n(losss))\n",
    "\n",
    "\n",
    "class CShapNN(ShapNN):\n",
    "    \n",
    "    def __init__(self, mode, hidden_units=[100], kernel_sizes=[], \n",
    "                 strides=None, channels=[], learning_rate=0.001, \n",
    "                 dropout = 0., activation=None, initializer=None, global_averaging=False,\n",
    "                weight_decay=0.0001, optimizer='adam', batch_size=128, \n",
    "                warm_start=False, max_epochs=100, validation_fraction=0.1,\n",
    "                early_stopping=0, address=None, test_batch_size=1000, random_seed=666):\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.test_batch_size = test_batch_size\n",
    "        self.kernels = []#FIXIT\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.channels = channels\n",
    "        self.global_averaging = global_averaging\n",
    "        assert len(channels)==len(kernel_sizes), 'Invalid channels or kernel_sizes'\n",
    "        if strides is None:\n",
    "            self.strides = [1] * len(kernel_sizes)\n",
    "        else:\n",
    "            self.strides = strides\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_units = hidden_units\n",
    "        self.initializer = initializer\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.weight_decay = weight_decay\n",
    "        self.optimizer = optimizer\n",
    "        self.learning_rate = learning_rate\n",
    "        self.warm_start = warm_start\n",
    "        self.max_epochs = max_epochs\n",
    "        self.early_stopping = early_stopping\n",
    "        self.validation_fraction = validation_fraction\n",
    "        self.address = address\n",
    "        self._extra_train_ops = []\n",
    "        self.random_seed = random_seed\n",
    "        self.graph = tf.Graph()\n",
    "        self.is_built = False\n",
    "        with self.graph.as_default():\n",
    "            config = tf.ConfigProto()\n",
    "            config.gpu_options.allow_growth=True\n",
    "            self.sess = tf.Session(config=config)\n",
    "            \n",
    "    def _conv(self, x, filter_size, out_filters, strides, activation=None):\n",
    "        \n",
    "        in_filters = int(x.get_shape()[-1])\n",
    "        n = filter_size * filter_size * out_filters\n",
    "        kernel = tf.get_variable(\n",
    "            'DW', [filter_size, filter_size, in_filters, out_filters],\n",
    "            tf.float32, initializer=tf.random_normal_initializer(\n",
    "                stddev=np.sqrt(2.0/n)))\n",
    "        self.kernels.append(kernel)\n",
    "        x = tf.nn.conv2d(x, kernel, strides, padding='SAME')\n",
    "        if activation:\n",
    "            x = activation(x)\n",
    "        return x\n",
    "    \n",
    "    def _stride_arr(self, stride):\n",
    "        \n",
    "        if isinstance(stride, int):\n",
    "            return [1, stride, stride, 1]\n",
    "        if len(stride)==2:\n",
    "            return [1, stride[0], stride[1], 1]\n",
    "        if len(stride)==4:\n",
    "            return stride\n",
    "        raise ValueError('Invalid value!')  \n",
    "        \n",
    "    def _build_model(self, X, y):\n",
    "        \n",
    "        \n",
    "        if self.initializer is None:\n",
    "            initializer = tf.initializers.variance_scaling(distribution='uniform')\n",
    "        if self.activation is None:\n",
    "            activation = lambda x: tf.nn.relu(x)\n",
    "        self.input_ph = tf.placeholder(dtype=tf.float32, shape=(None,) + X.shape[1:], name='input')\n",
    "        self.dropout_ph = tf.placeholder_with_default(\n",
    "            tf.constant(0., dtype=tf.float32), shape=(), name='dropout')\n",
    "        if self.mode=='regression':\n",
    "            self.labels = tf.placeholder(dtype=tf.float32, shape=(None, ), name='label')\n",
    "        else:\n",
    "            self.labels = tf.placeholder(dtype=tf.int32, shape=(None, ), name='label')\n",
    "        if len(X.shape[1:]) == 2:\n",
    "            x = tf.reshape(self.input_ph, [-1, X.shape[0], X.shape[1], 1])\n",
    "        else:\n",
    "            x = self.input_ph\n",
    "        for layer, (kernel_size, channels, stride) in enumerate(zip(\n",
    "            self.kernel_sizes, self.channels, self.strides)):\n",
    "            with tf.variable_scope('conv_{}'.format(layer)):\n",
    "                x = self._conv(x, kernel_size, channels, self._stride_arr(stride), activation=activation)\n",
    "        if self.global_averaging:\n",
    "            x = tf.reduce_mean(x, axis=(1,2))\n",
    "        else:\n",
    "            x = tf.reshape(x, shape=(-1, np.prod(x.get_shape()[1:])))\n",
    "        for layer, hidden_unit in enumerate(self.hidden_units):\n",
    "            with tf.variable_scope('dense_{}'.format(layer)):\n",
    "                x = self._dense(x, hidden_unit, dropout=self.dropout_ph, \n",
    "                           initializer=self.initializer, activation=activation)\n",
    "                \n",
    "        with tf.variable_scope('final'):\n",
    "            self.prelogits = x\n",
    "            self._final_layer(self.prelogits, len(set(y)), self.mode)\n",
    "        self._build_train_op()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81469b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.unicode in file /dartfs-hpc/rc/home/d/f0036rd/.conda/envs/SHAPenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 112 ('text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key text.latex.preview in file /dartfs-hpc/rc/home/d/f0036rd/.conda/envs/SHAPenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 125 ('text.latex.preview : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key mathtext.fallback_to_cm in file /dartfs-hpc/rc/home/d/f0036rd/.conda/envs/SHAPenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 157 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.jpeg_quality in file /dartfs-hpc/rc/home/d/f0036rd/.conda/envs/SHAPenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 420 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.frameon in file /dartfs-hpc/rc/home/d/f0036rd/.conda/envs/SHAPenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 423 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key pgf.debug in file /dartfs-hpc/rc/home/d/f0036rd/.conda/envs/SHAPenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 444 ('pgf.debug           : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file /dartfs-hpc/rc/home/d/f0036rd/.conda/envs/SHAPenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 475 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file /dartfs-hpc/rc/home/d/f0036rd/.conda/envs/SHAPenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 476 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key keymap.all_axes in file /dartfs-hpc/rc/home/d/f0036rd/.conda/envs/SHAPenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 493 ('keymap.all_axes : a                 # enable all axes')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_path in file /dartfs-hpc/rc/home/d/f0036rd/.conda/envs/SHAPenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 504 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_args in file /dartfs-hpc/rc/home/d/f0036rd/.conda/envs/SHAPenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 506 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import inspect\n",
    "from scipy.stats import logistic\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.base import clone\n",
    "import inspect\n",
    "#from Shapley import ShapNN, CShapNN\n",
    "from multiprocessing import dummy as multiprocessing\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "        \n",
    "def convergence_plots(marginals):\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = 15,15\n",
    "    for i, idx in enumerate(np.arange(min(25, marginals.shape[-1]))):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.plot(np.cumsum(marginals[:, idx])/np.arange(1, len(marginals)+1))    \n",
    "        \n",
    "    \n",
    "def is_integer(array):\n",
    "    return (np.equal(np.mod(array, 1), 0).mean()==1)\n",
    "\n",
    "\n",
    "def is_fitted(model):\n",
    "        \"\"\"Checks if model object has any attributes ending with an underscore\"\"\"\n",
    "        return 0 < len( [k for k,v in inspect.getmembers(model) if k.endswith('_') and not k.startswith('__')] )\n",
    "\n",
    "\n",
    "def return_model(mode, **kwargs):\n",
    "    \n",
    "    \n",
    "    if inspect.isclass(mode):\n",
    "        assert getattr(mode, 'fit', None) is not None, 'Custom model family should have a fit() method'\n",
    "        model = mode(**kwargs)\n",
    "    elif mode=='logistic':\n",
    "        solver = kwargs.get('solver', 'liblinear')\n",
    "        n_jobs = kwargs.get('n_jobs', None)\n",
    "        max_iter = kwargs.get('max_iter', 5000)\n",
    "        model = LogisticRegression(solver=solver, n_jobs=n_jobs, \n",
    "                                 max_iter=max_iter, random_state=666)\n",
    "    elif mode=='Tree':\n",
    "        model = DecisionTreeClassifier(random_state=666)\n",
    "    elif mode=='RandomForest':\n",
    "        n_estimators = kwargs.get('n_estimators', 50)\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, random_state=666)\n",
    "    elif mode=='GB':\n",
    "        n_estimators = kwargs.get('n_estimators', 50)\n",
    "        model = GradientBoostingClassifier(n_estimators=n_estimators, random_state=666)\n",
    "    elif mode=='AdaBoost':\n",
    "        n_estimators = kwargs.get('n_estimators', 50)\n",
    "        model = AdaBoostClassifier(n_estimators=n_estimators, random_state=666)\n",
    "    elif mode=='SVC':\n",
    "        kernel = kwargs.get('kernel', 'rbf')\n",
    "        model = SVC(kernel=kernel, random_state=666)\n",
    "    elif mode=='LinearSVC':\n",
    "        model = LinearSVC(loss='hinge', random_state=666)\n",
    "    elif mode=='GP':\n",
    "        model = GaussianProcessClassifier(random_state=666)\n",
    "    elif mode=='KNN':\n",
    "        n_neighbors = kwargs.get('n_neighbors', 5)\n",
    "        model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    elif mode=='NB':\n",
    "        model = MultinomialNB()\n",
    "    elif mode=='linear':\n",
    "        model = LinearRegression(random_state=666)\n",
    "    elif mode=='ridge':\n",
    "        alpha = kwargs.get('alpha', 1.0)\n",
    "        model = Ridge(alpha=alpha, random_state=666)\n",
    "    elif 'conv' in mode:\n",
    "        tf.reset_default_graph()\n",
    "        address = kwargs.get('address', 'weights/conv')\n",
    "        hidden_units = kwargs.get('hidden_layer_sizes', [20])\n",
    "        activation = kwargs.get('activation', 'relu')\n",
    "        weight_decay = kwargs.get('weight_decay', 1e-4)\n",
    "        learning_rate = kwargs.get('learning_rate', 0.001)\n",
    "        max_iter = kwargs.get('max_iter', 1000)\n",
    "        early_stopping= kwargs.get('early_stopping', 10)\n",
    "        warm_start = kwargs.get('warm_start', False)\n",
    "        batch_size = kwargs.get('batch_size', 256)\n",
    "        kernel_sizes = kwargs.get('kernel_sizes', [5])\n",
    "        strides = kwargs.get('strides', [5])\n",
    "        channels = kwargs.get('channels', [1])\n",
    "        validation_fraction = kwargs.get('validation_fraction', 0.)\n",
    "        global_averaging = kwargs.get('global_averaging', 0.)\n",
    "        optimizer = kwargs.get('optimizer', 'sgd')\n",
    "        if mode=='conv':\n",
    "            model = CShapNN(mode='classification', batch_size=batch_size, max_epochs=max_iter,\n",
    "                          learning_rate=learning_rate, \n",
    "                          weight_decay=weight_decay, validation_fraction=validation_fraction,\n",
    "                          early_stopping=early_stopping,\n",
    "                         optimizer=optimizer, warm_start=warm_start, address=address,\n",
    "                          hidden_units=hidden_units,\n",
    "                          strides=strides, global_averaging=global_averaging,\n",
    "                         kernel_sizes=kernel_sizes, channels=channels, random_seed=666)\n",
    "        elif mode=='conv_reg':\n",
    "            model = CShapNN(mode='regression', batch_size=batch_size, max_epochs=max_iter,\n",
    "                          learning_rate=learning_rate, \n",
    "                          weight_decay=weight_decay, validation_fraction=validation_fraction,\n",
    "                          early_stopping=early_stopping,\n",
    "                         optimizer=optimizer, warm_start=warm_start, address=address,\n",
    "                          hidden_units=hidden_units,\n",
    "                          strides=strides, global_averaging=global_averaging,\n",
    "                         kernel_sizes=kernel_sizes, channels=channels, random_seed=666)\n",
    "    elif 'NN' in mode:\n",
    "        solver = kwargs.get('solver', 'adam')\n",
    "        hidden_layer_sizes = kwargs.get('hidden_layer_sizes', (20,))\n",
    "        if isinstance(hidden_layer_sizes, list):\n",
    "            hidden_layer_sizes = list(hidden_layer_sizes)\n",
    "        activation = kwargs.get('activation', 'relu')\n",
    "        learning_rate_init = kwargs.get('learning_rate', 0.001)\n",
    "        max_iter = kwargs.get('max_iter', 5000)\n",
    "        early_stopping= kwargs.get('early_stopping', False)\n",
    "        warm_start = kwargs.get('warm_start', False)\n",
    "        if mode=='NN':\n",
    "            model = MLPClassifier(solver=solver, hidden_layer_sizes=hidden_layer_sizes,\n",
    "                                activation=activation, learning_rate_init=learning_rate_init,\n",
    "                                warm_start = warm_start, max_iter=max_iter,\n",
    "                                early_stopping=early_stopping)\n",
    "        if mode=='NN_reg':\n",
    "            model = MLPRegressor(solver=solver, hidden_layer_sizes=hidden_layer_sizes,\n",
    "                                activation=activation, learning_rate_init=learning_rate_init,\n",
    "                                warm_start = warm_start, max_iter=max_iter, early_stopping=early_stopping)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode!\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def generate_features(latent, dependency):\n",
    "\n",
    "    features = []\n",
    "    n = latent.shape[0]\n",
    "    exp = latent\n",
    "    holder = latent\n",
    "    for order in range(1,dependency+1):\n",
    "        features.append(np.reshape(holder,[n,-1]))\n",
    "        exp = np.expand_dims(exp,-1)\n",
    "        holder = exp * np.expand_dims(holder,1)\n",
    "    return np.concatenate(features,axis=-1)  \n",
    "\n",
    "\n",
    "def label_generator(problem, X, param, difficulty=1, beta=None, important=None):\n",
    "        \n",
    "    if important is None or important > X.shape[-1]:\n",
    "        important = X.shape[-1]\n",
    "    dim_latent = sum([important**i for i in range(1, difficulty+1)])\n",
    "    if beta is None:\n",
    "        beta = np.random.normal(size=[1, dim_latent])\n",
    "    important_dims = np.random.choice(X.shape[-1], important, replace=False)\n",
    "    funct_init = lambda inp: np.sum(beta * generate_features(inp[:,important_dims], difficulty), -1)\n",
    "    batch_size = max(100, min(len(X), 10000000//dim_latent))\n",
    "    y_true = np.zeros(len(X))\n",
    "    while True:\n",
    "        try:\n",
    "            for itr in range(int(np.ceil(len(X)/batch_size))):\n",
    "                y_true[itr * batch_size: (itr+1) * batch_size] = funct_init(\n",
    "                    X[itr * batch_size: (itr+1) * batch_size])\n",
    "            break\n",
    "        except MemoryError:\n",
    "            batch_size = batch_size//2\n",
    "    mean, std = np.mean(y_true), np.std(y_true)\n",
    "    funct = lambda x: (np.sum(beta * generate_features(\n",
    "        x[:, important_dims], difficulty), -1) - mean) / std\n",
    "    y_true = (y_true - mean)/std\n",
    "    if problem is 'classification':\n",
    "        y_true = logistic.cdf(param * y_true)\n",
    "        y = (np.random.random(X.shape[0]) < y_true).astype(int)\n",
    "    elif problem is 'regression':\n",
    "        y = y_true + param * np.random.normal(size=len(y_true))\n",
    "    else:\n",
    "        raise ValueError('Invalid problem specified!')\n",
    "    return beta, y, y_true, funct\n",
    "\n",
    "\n",
    "def one_iteration(clf, X, y, X_test, y_test, mean_score, tol=0.0, c=None, metric='accuracy'):\n",
    "    \"\"\"Runs one iteration of TMC-Shapley.\"\"\"\n",
    "    \n",
    "    if metric == 'auc':\n",
    "        def score_func(clf, a, b):\n",
    "            return roc_auc_score(b, clf.predict_proba(a)[:,1])\n",
    "    elif metric == 'accuracy':\n",
    "        def score_func(clf, a, b):\n",
    "            return clf.score(a, b)\n",
    "    else:\n",
    "        raise ValueError(\"Wrong metric!\")  \n",
    "    if c is None:\n",
    "        c = {i:np.array([i]) for i in range(len(X))}\n",
    "    idxs, marginal_contribs = np.random.permutation(len(c.keys())), np.zeros(len(X))\n",
    "    new_score = np.max(np.bincount(y)) * 1./len(y) if np.mean(y//1 == y/1)==1 else 0.\n",
    "    start = 0\n",
    "    if start:\n",
    "        X_batch, y_batch =\\\n",
    "        np.concatenate([X[c[idx]] for idx in idxs[:start]]), np.concatenate([y[c[idx]] for idx in idxs[:start]])\n",
    "    else:\n",
    "        X_batch, y_batch = np.zeros((0,) +  tuple(X.shape[1:])), np.zeros(0).astype(int)\n",
    "    for n, idx in enumerate(idxs[start:]):\n",
    "        try:\n",
    "            clf = clone(clf)\n",
    "        except:\n",
    "            clf.fit(np.zeros((0,) +  X.shape[1:]), y)\n",
    "        old_score = new_score\n",
    "        X_batch, y_batch = np.concatenate([X_batch, X[c[idx]]]), np.concatenate([y_batch, y[c[idx]]])\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            try:\n",
    "                clf.fit(X_batch, y_batch)\n",
    "                temp_score = score_func(clf, X_test, y_test)\n",
    "                if temp_score>-1 and temp_score<1.: #Removing measningless r2 scores\n",
    "                    new_score = temp_score\n",
    "            except:\n",
    "                continue\n",
    "        marginal_contribs[c[idx]] = (new_score - old_score)/len(c[idx])\n",
    "        if np.abs(new_score - mean_score)/mean_score < tol:\n",
    "            break\n",
    "    return marginal_contribs, idxs\n",
    "\n",
    "\n",
    "def marginals(clf, X, y, X_test, y_test, c=None, tol=0., trials=3000, mean_score=None, metric='accuracy'):\n",
    "    \n",
    "    if metric == 'auc':\n",
    "        def score_func(clf, a, b):\n",
    "            return roc_auc_score(b, clf.predict_proba(a)[:,1])\n",
    "    elif metric == 'accuracy':\n",
    "        def score_func(clf, a, b):\n",
    "            return clf.score(a, b)\n",
    "    else:\n",
    "        raise ValueError(\"Wrong metric!\")  \n",
    "    if mean_score is None:\n",
    "        accs = []\n",
    "        for _ in range(100):\n",
    "            bag_idxs = np.random.choice(len(y_test), len(y_test))\n",
    "            accs.append(score_func(clf, X_test[bag_idxs], y_test[bag_idxs]))\n",
    "        mean_score = np.mean(accs)\n",
    "    marginals, idxs = [], []\n",
    "    for trial in range(trials):\n",
    "        if 10*(trial+1)/trials % 1 == 0:\n",
    "            print('{} out of {}'.format(trial + 1, trials))\n",
    "        marginal, idx = one_iteration(clf, X, y, X_test, y_test, mean_score, tol=tol, c=c, metric=metric)\n",
    "        marginals.append(marginal)\n",
    "        idxs.append(idx)\n",
    "    return np.array(marginals), np.array(idxs)\n",
    "\n",
    "def shapley(mode, X, y, X_test, y_test, stop=None, tol=0., trials=3000, **kwargs):\n",
    "    \n",
    "    try:\n",
    "        vals = np.zeros(len(X))\n",
    "        example_idxs = np.random.choice(len(X), min(25, len(X)), replace=False)\n",
    "        example_marginals = np.zeros((trials, len(example_idxs)))\n",
    "        for i in range(trials):\n",
    "            print(i)\n",
    "            output = one_pass(mode, X, y, X_test, y_test, tol=tol, stop=stop, **kwargs)\n",
    "            example_marginals[i] = output[0][example_idxs]\n",
    "            vals = vals/(i+1) + output[0]/(i+1)\n",
    "        return vals, example_marginals\n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted!')\n",
    "        return vals, example_marginals\n",
    "\n",
    "def early_stopping(marginals, idxs, stopping):\n",
    "    \n",
    "    stopped_marginals = np.zeros_like(marginals)\n",
    "    for i in range(len(marginals)):\n",
    "        stopped_marginals[i][idxs[i][:stopping]] = marginals[i][idxs[i][:stopping]]\n",
    "    return np.mean(stopped_marginals, 0)\n",
    "\n",
    "def error(mem):\n",
    "    \n",
    "    if len(mem) < 100:\n",
    "        return 1.0\n",
    "    all_vals = (np.cumsum(mem, 0)/np.reshape(np.arange(1, len(mem)+1), (-1,1)))[-100:]\n",
    "    errors = np.mean(np.abs(all_vals[-100:] - all_vals[-1:])/(np.abs(all_vals[-1:]) + 1e-12), -1)\n",
    "    return np.max(errors)\n",
    "\n",
    "def my_accuracy_score(clf, X, y):\n",
    "    \n",
    "    probs = clf.predict_proba(X)\n",
    "    predictions = np.argmax(probs, -1)\n",
    "    return np.mean(np.equal(predictions, y))\n",
    "\n",
    "def my_f1_score(clf, X, y):\n",
    "    \n",
    "    predictions = clf.predict(x)\n",
    "    if len(set(y)) == 2:\n",
    "        return f1_score(y, predictions)\n",
    "    return f1_score(y, predictions, average='macro')\n",
    "\n",
    "def my_auc_score(clf, X, y):\n",
    "    \n",
    "    probs = clf.predict_proba(X)\n",
    "    true_probs = probs[np.arange(len(y)), y]\n",
    "    return roc_auc_score(y, true_probs)\n",
    "\n",
    "def my_xe_score(clf, X, y):\n",
    "    \n",
    "    probs = clf.predict_proba(X)\n",
    "    true_probs = probs[np.arange(len(y)), y]\n",
    "    true_log_probs = np.log(np.clip(true_probs, 1e-12, None))\n",
    "    return np.mean(true_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514fa4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec92ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#______________________________________PEP8____________________________________\n",
    "#_______________________________________________________________________\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "#from shap_utils import *\n",
    "#from Shapley import ShapNN\n",
    "from scipy.stats import spearmanr\n",
    "#import shutil\n",
    "from sklearn.base import clone\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import itertools\n",
    "import inspect\n",
    "import _pickle as pkl\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "class DShap(object):\n",
    "    \n",
    "    def __init__(self, X, y, X_test, y_test, num_test, sources=None, \n",
    "                 sample_weight=None, directory=None, problem='classification',\n",
    "                 model_family='logistic', metric='accuracy', seed=None,\n",
    "                 overwrite=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: Data covariates\n",
    "            y: Data labels\n",
    "            X_test: Test+Held-out covariates\n",
    "            y_test: Test+Held-out labels\n",
    "            sources: An array or dictionary assiging each point to its group.\n",
    "                If None, evey points gets its individual value.\n",
    "            samples_weights: Weight of train samples in the loss function\n",
    "                (for models where weighted training method is enabled.)\n",
    "            num_test: Number of data points used for evaluation metric.\n",
    "            directory: Directory to save results and figures.\n",
    "            problem: \"Classification\" or \"Regression\"(Not implemented yet.)\n",
    "            model_family: The model family used for learning algorithm\n",
    "            metric: Evaluation metric\n",
    "            seed: Random seed. When running parallel monte-carlo samples,\n",
    "                we initialize each with a different seed to prevent getting \n",
    "                same permutations.\n",
    "            overwrite: Delete existing data and start computations from \n",
    "                scratch\n",
    "            **kwargs: Arguments of the model\n",
    "        \"\"\"\n",
    "            \n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            tf.random.set_random_seed(seed)\n",
    "        self.problem = problem\n",
    "        self.model_family = model_family\n",
    "        self.metric = metric\n",
    "        self.directory = directory\n",
    "        self.hidden_units = kwargs.get('hidden_layer_sizes', [])\n",
    "        if self.model_family is 'logistic':\n",
    "            self.hidden_units = []\n",
    "        if self.directory is not None:\n",
    "            if overwrite and os.path.exists(directory):\n",
    "                tf.gfile.DeleteRecursively(directory)\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)  \n",
    "                os.makedirs(os.path.join(directory, 'weights'))\n",
    "                os.makedirs(os.path.join(directory, 'plots'))\n",
    "            self._initialize_instance(X, y, X_test, y_test, num_test, \n",
    "                                      sources, sample_weight)\n",
    "        if len(set(self.y)) > 2:\n",
    "            assert self.metric != 'f1', 'Invalid metric for multiclass!'\n",
    "            assert self.metric != 'auc', 'Invalid metric for multiclass!'\n",
    "        is_regression = (np.mean(self.y//1 == self.y) != 1)\n",
    "        is_regression = is_regression or isinstance(self.y[0], np.float32)\n",
    "        self.is_regression = is_regression or isinstance(self.y[0], np.float64)\n",
    "        if self.is_regression:\n",
    "            warnings.warn(\"Regression problem is no implemented.\")\n",
    "        self.model = return_model(self.model_family, **kwargs)\n",
    "        self.random_score = self.init_score(self.metric)\n",
    "            \n",
    "    def _initialize_instance(self, X, y, X_test, y_test, num_test, \n",
    "                             sources=None, sample_weight=None):\n",
    "        \"\"\"Loads or creates sets of data.\"\"\"      \n",
    "        if sources is None:\n",
    "            sources = {i:np.array([i]) for i in range(len(X))}\n",
    "        elif not isinstance(sources, dict):\n",
    "            sources = {i:np.where(sources==i)[0] for i in set(sources)}\n",
    "        data_dir = os.path.join(self.directory, 'data.pkl')\n",
    "        if os.path.exists(data_dir):\n",
    "            self._load_dataset(data_dir)\n",
    "        else:\n",
    "            self.X_heldout = X_test[:-num_test]\n",
    "            self.y_heldout = y_test[:-num_test]\n",
    "            self.X_test = X_test[-num_test:]\n",
    "            self.y_test = y_test[-num_test:]\n",
    "            self.X, self.y, self.sources = X, y, sources\n",
    "            self.sample_weight = sample_weight\n",
    "            data_dic = {'X': self.X, 'y': self.y, 'X_test': self.X_test,\n",
    "                     'y_test': self.y_test, 'X_heldout': self.X_heldout,\n",
    "                     'y_heldout':self.y_heldout, 'sources': self.sources}\n",
    "            if sample_weight is not None:\n",
    "                data_dic['sample_weight'] = sample_weight\n",
    "                warnings.warn(\"Sample weight not implemented for G-Shapley\")\n",
    "            pkl.dump(data_dic, open(data_dir, 'wb'))        \n",
    "        loo_dir = os.path.join(self.directory, 'loo.pkl')\n",
    "        self.vals_loo = None\n",
    "        if os.path.exists(loo_dir):\n",
    "            self.vals_loo = pkl.load(open(loo_dir, 'rb'))['loo']\n",
    "        n_sources = len(self.X) if self.sources is None else len(self.sources)\n",
    "        n_points = len(self.X)\n",
    "        self.tmc_number, self.g_number = self._which_parallel(self.directory)\n",
    "        self._create_results_placeholder(\n",
    "            self.directory, self.tmc_number, self.g_number,\n",
    "            n_points, n_sources, self.model_family)\n",
    "        \n",
    "    def _create_results_placeholder(self, directory, tmc_number, g_number,\n",
    "                                   n_points, n_sources, model_family):\n",
    "        tmc_dir = os.path.join(\n",
    "            directory, \n",
    "            'mem_tmc_{}.pkl'.format(tmc_number.zfill(4))\n",
    "        )\n",
    "        g_dir = os.path.join(\n",
    "            directory, \n",
    "            'mem_g_{}.pkl'.format(g_number.zfill(4))\n",
    "        )\n",
    "        self.mem_tmc = np.zeros((0, n_points))\n",
    "        self.mem_g = np.zeros((0, n_points))\n",
    "        self.idxs_tmc = np.zeros((0, n_sources), int)\n",
    "        self.idxs_g = np.zeros((0, n_sources), int)\n",
    "        pkl.dump({'mem_tmc': self.mem_tmc, 'idxs_tmc': self.idxs_tmc}, \n",
    "                 open(tmc_dir, 'wb'))\n",
    "        if model_family not in ['logistic', 'NN']:\n",
    "            return\n",
    "        pkl.dump({'mem_g': self.mem_g, 'idxs_g': self.idxs_g}, \n",
    "                 open(g_dir, 'wb'))\n",
    "        \n",
    "    def _load_dataset(self, data_dir):\n",
    "        '''Load the different sets of data if already exists.'''\n",
    "        data_dic = pkl.load(open(data_dir, 'rb'))\n",
    "        self.X_heldout = data_dic['X_heldout']\n",
    "        self.y_heldout = data_dic['y_heldout']\n",
    "        self.X_test = data_dic['X_test']\n",
    "        self.y_test = data_dic['y_test']\n",
    "        self.X = data_dic['X'] \n",
    "        self.y = data_dic['y']\n",
    "        self.sources = data_dic['sources']\n",
    "        if 'sample_weight' in data_dic.keys():\n",
    "            self.sample_weight = data_dic['sample_weight']\n",
    "        else:\n",
    "            self.sample_weight = None\n",
    "        \n",
    "    def _which_parallel(self, directory):\n",
    "        '''Prevent conflict with parallel runs.'''\n",
    "        previous_results = os.listdir(directory)\n",
    "        tmc_nmbrs = [int(name.split('.')[-2].split('_')[-1])\n",
    "                      for name in previous_results if 'mem_tmc' in name]\n",
    "        g_nmbrs = [int(name.split('.')[-2].split('_')[-1])\n",
    "                     for name in previous_results if 'mem_g' in name]        \n",
    "        tmc_number = str(np.max(tmc_nmbrs) + 1) if len(tmc_nmbrs) else '0' \n",
    "        g_number = str(np.max(g_nmbrs) + 1) if len(g_nmbrs) else '0' \n",
    "        return tmc_number, g_number\n",
    "    \n",
    "    def init_score(self, metric):\n",
    "        \"\"\" Gives the value of an initial untrained model.\"\"\"\n",
    "        if metric == 'accuracy':\n",
    "            hist = np.bincount(self.y_test).astype(float)/len(self.y_test)\n",
    "            return np.max(hist)\n",
    "        if metric == 'f1':\n",
    "            rnd_f1s = []\n",
    "            for _ in range(1000):\n",
    "                rnd_y = np.random.permutation(self.y_test)\n",
    "                rnd_f1s.append(f1_score(self.y_test, rnd_y))\n",
    "            return np.mean(rnd_f1s)\n",
    "        if metric == 'auc':\n",
    "            return 0.5\n",
    "        random_scores = []\n",
    "        for _ in range(100):\n",
    "            rnd_y = np.random.permutation(self.y)\n",
    "            if self.sample_weight is None:\n",
    "                self.model.fit(self.X, rnd_y)\n",
    "            else:\n",
    "                self.model.fit(self.X, rnd_y, \n",
    "                               sample_weight=self.sample_weight)\n",
    "            random_scores.append(self.value(self.model, metric))\n",
    "        return np.mean(random_scores)\n",
    "        \n",
    "    def value(self, model, metric=None, X=None, y=None):\n",
    "        \"\"\"Computes the values of the given model.\n",
    "        Args:\n",
    "            model: The model to be evaluated.\n",
    "            metric: Valuation metric. If None the object's default\n",
    "                metric is used.\n",
    "            X: Covariates, valuation is performed on a data \n",
    "                different from test set.\n",
    "            y: Labels, if valuation is performed on a data \n",
    "                different from test set.\n",
    "            \"\"\"\n",
    "        if metric is None:\n",
    "            metric = self.metric\n",
    "        if X is None:\n",
    "            X = self.X_test\n",
    "        if y is None:\n",
    "            y = self.y_test\n",
    "        if inspect.isfunction(metric):\n",
    "            return metric(model, X, y)\n",
    "        if metric == 'accuracy':\n",
    "            return model.score(X, y)\n",
    "        if metric == 'f1':\n",
    "            assert len(set(y)) == 2, 'Data has to be binary for f1 metric.'\n",
    "            return f1_score(y, model.predict(X))\n",
    "        if metric == 'auc':\n",
    "            assert len(set(y)) == 2, 'Data has to be binary for auc metric.'\n",
    "            return my_auc_score(model, X, y)\n",
    "        if metric == 'xe':\n",
    "            return my_xe_score(model, X, y)\n",
    "        raise ValueError('Invalid metric!')\n",
    "        \n",
    "    def run(self, save_every, err, tolerance=0.01, g_run=True, loo_run=True):\n",
    "        \"\"\"Calculates data sources(points) values.\n",
    "        \n",
    "        Args:\n",
    "            save_every: save marginal contrivbutions every n iterations.\n",
    "            err: stopping criteria.\n",
    "            tolerance: Truncation tolerance. If None, it's computed.\n",
    "            g_run: If True, computes G-Shapley values.\n",
    "            loo_run: If True, computes and saves leave-one-out scores.\n",
    "        \"\"\"\n",
    "        if loo_run:\n",
    "            try:\n",
    "                len(self.vals_loo)\n",
    "            except:\n",
    "                self.vals_loo = self._calculate_loo_vals(sources=self.sources)\n",
    "                self.save_results(overwrite=True)\n",
    "        print('LOO values calculated!')\n",
    "        tmc_run = True \n",
    "        g_run = g_run and self.model_family in ['logistic', 'NN']\n",
    "        while tmc_run or g_run:\n",
    "            if g_run:\n",
    "                if error(self.mem_g) < err:\n",
    "                    g_run = False\n",
    "                else:\n",
    "                    self._g_shap(save_every, sources=self.sources)\n",
    "                    self.vals_g = np.mean(self.mem_g, 0)\n",
    "            if tmc_run:\n",
    "                if error(self.mem_tmc) < err:\n",
    "                    tmc_run = False\n",
    "                else:\n",
    "                    self._tmc_shap(\n",
    "                        save_every, \n",
    "                        tolerance=tolerance, \n",
    "                        sources=self.sources\n",
    "                    )\n",
    "                    self.vals_tmc = np.mean(self.mem_tmc, 0)\n",
    "            if self.directory is not None:\n",
    "                self.save_results()\n",
    "            \n",
    "    def save_results(self, overwrite=False):\n",
    "        \"\"\"Saves results computed so far.\"\"\"\n",
    "        if self.directory is None:\n",
    "            return\n",
    "        loo_dir = os.path.join(self.directory, 'loo.pkl')\n",
    "        if not os.path.exists(loo_dir) or overwrite:\n",
    "            pkl.dump({'loo': self.vals_loo}, open(loo_dir, 'wb'))\n",
    "        tmc_dir = os.path.join(\n",
    "            self.directory, \n",
    "            'mem_tmc_{}.pkl'.format(self.tmc_number.zfill(4))\n",
    "        )\n",
    "        g_dir = os.path.join(\n",
    "            self.directory, \n",
    "            'mem_g_{}.pkl'.format(self.g_number.zfill(4))\n",
    "        )  \n",
    "        pkl.dump({'mem_tmc': self.mem_tmc, 'idxs_tmc': self.idxs_tmc}, \n",
    "                 open(tmc_dir, 'wb'))\n",
    "        pkl.dump({'mem_g': self.mem_g, 'idxs_g': self.idxs_g}, \n",
    "                 open(g_dir, 'wb'))  \n",
    "        \n",
    "    def _tmc_shap(self, iterations, tolerance=None, sources=None):\n",
    "        \"\"\"Runs TMC-Shapley algorithm.\n",
    "        \n",
    "        Args:\n",
    "            iterations: Number of iterations to run.\n",
    "            tolerance: Truncation tolerance ratio.\n",
    "            sources: If values are for sources of data points rather than\n",
    "                   individual points. In the format of an assignment array\n",
    "                   or dict.\n",
    "        \"\"\"\n",
    "        if sources is None:\n",
    "            sources = {i: np.array([i]) for i in range(len(self.X))}\n",
    "        elif not isinstance(sources, dict):\n",
    "            sources = {i: np.where(sources == i)[0] for i in set(sources)}\n",
    "        model = self.model\n",
    "        try:\n",
    "            self.mean_score\n",
    "        except:\n",
    "            self._tol_mean_score()\n",
    "        if tolerance is None:\n",
    "            tolerance = self.tolerance         \n",
    "        marginals, idxs = [], []\n",
    "        for iteration in range(iterations):\n",
    "            if 10*(iteration+1)/iterations % 1 == 0:\n",
    "                print('{} out of {} TMC_Shapley iterations.'.format(\n",
    "                    iteration + 1, iterations))\n",
    "            marginals, idxs = self.one_iteration(\n",
    "                tolerance=tolerance, \n",
    "                sources=sources\n",
    "            )\n",
    "            self.mem_tmc = np.concatenate([\n",
    "                self.mem_tmc, \n",
    "                np.reshape(marginals, (1,-1))\n",
    "            ])\n",
    "            self.idxs_tmc = np.concatenate([\n",
    "                self.idxs_tmc, \n",
    "                np.reshape(idxs, (1,-1))\n",
    "            ])\n",
    "        \n",
    "    def _tol_mean_score(self):\n",
    "        \"\"\"Computes the average performance and its error using bagging.\"\"\"\n",
    "        scores = []\n",
    "        self.restart_model()\n",
    "        for _ in range(1):\n",
    "            if self.sample_weight is None:\n",
    "                self.model.fit(self.X, self.y)\n",
    "            else:\n",
    "                self.model.fit(self.X, self.y,\n",
    "                              sample_weight=self.sample_weight)\n",
    "            for _ in range(100):\n",
    "                bag_idxs = np.random.choice(len(self.y_test), len(self.y_test))\n",
    "                scores.append(self.value(\n",
    "                    self.model, \n",
    "                    metric=self.metric,\n",
    "                    X=self.X_test[bag_idxs], \n",
    "                    y=self.y_test[bag_idxs]\n",
    "                ))\n",
    "        self.tol = np.std(scores)\n",
    "        self.mean_score = np.mean(scores)\n",
    "        \n",
    "    def one_iteration(self, tolerance, sources=None):\n",
    "        \"\"\"Runs one iteration of TMC-Shapley algorithm.\"\"\"\n",
    "        if sources is None:\n",
    "            sources = {i: np.array([i]) for i in range(len(self.X))}\n",
    "        elif not isinstance(sources, dict):\n",
    "            sources = {i: np.where(sources == i)[0] for i in set(sources)}\n",
    "        idxs = np.random.permutation(len(sources))\n",
    "        marginal_contribs = np.zeros(len(self.X))\n",
    "        X_batch = np.zeros((0,) + tuple(self.X.shape[1:]))\n",
    "        y_batch = np.zeros(0, int)\n",
    "        sample_weight_batch = np.zeros(0)\n",
    "        truncation_counter = 0\n",
    "        new_score = self.random_score\n",
    "        for n, idx in enumerate(idxs):\n",
    "            old_score = new_score\n",
    "            X_batch = np.concatenate([X_batch, self.X[sources[idx]]])\n",
    "            y_batch = np.concatenate([y_batch, self.y[sources[idx]]])\n",
    "            if self.sample_weight is None:\n",
    "                sample_weight_batch = None\n",
    "            else:\n",
    "                sample_weight_batch = np.concatenate([\n",
    "                    sample_weight_batch, \n",
    "                    self.sample_weight[sources[idx]]\n",
    "                ])\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                if (self.is_regression \n",
    "                    or len(set(y_batch)) == len(set(self.y_test))): ##FIXIT\n",
    "                    self.restart_model()\n",
    "                    if sample_weight_batch is None:\n",
    "                        self.model.fit(X_batch, y_batch)\n",
    "                    else:\n",
    "                        self.model.fit(\n",
    "                            X_batch, \n",
    "                            y_batch,\n",
    "                            sample_weight = sample_weight_batch\n",
    "                        )\n",
    "                    new_score = self.value(self.model, metric=self.metric)       \n",
    "            marginal_contribs[sources[idx]] = (new_score - old_score)\n",
    "            marginal_contribs[sources[idx]] /= len(sources[idx])\n",
    "            distance_to_full_score = np.abs(new_score - self.mean_score)\n",
    "            if distance_to_full_score <= tolerance * self.mean_score:\n",
    "                truncation_counter += 1\n",
    "                if truncation_counter > 5:\n",
    "                    break\n",
    "            else:\n",
    "                truncation_counter = 0\n",
    "        return marginal_contribs, idxs\n",
    "    \n",
    "    def restart_model(self):\n",
    "        \n",
    "        try:\n",
    "            self.model = clone(self.model)\n",
    "        except:\n",
    "            self.model.fit(np.zeros((0,) + self.X.shape[1:]), self.y)\n",
    "        \n",
    "    def _one_step_lr(self):\n",
    "        \"\"\"Computes the best learning rate for G-Shapley algorithm.\"\"\"\n",
    "        if self.directory is None:\n",
    "            address = None\n",
    "        else:\n",
    "            address = os.path.join(self.directory, 'weights')\n",
    "        best_acc = 0.0\n",
    "        for i in np.arange(1, 5, 0.5):\n",
    "            model = ShapNN(\n",
    "                self.problem, batch_size=1, max_epochs=1, \n",
    "                learning_rate=10**(-i), weight_decay=0., \n",
    "                validation_fraction=0, optimizer='sgd', \n",
    "                warm_start=False, address=address, \n",
    "                hidden_units=self.hidden_units)\n",
    "            accs = []\n",
    "            for _ in range(10):\n",
    "                model.fit(np.zeros((0, self.X.shape[-1])), self.y)\n",
    "                model.fit(self.X, self.y)\n",
    "                accs.append(model.score(self.X_test, self.y_test))\n",
    "            if np.mean(accs) - np.std(accs) > best_acc:\n",
    "                best_acc  = np.mean(accs) - np.std(accs)\n",
    "                learning_rate = 10**(-i)\n",
    "        return learning_rate\n",
    "    \n",
    "    def _g_shap(self, iterations, err=None, learning_rate=None, sources=None):\n",
    "        \"\"\"Method for running G-Shapley algorithm.\n",
    "        \n",
    "        Args:\n",
    "            iterations: Number of iterations of the algorithm.\n",
    "            err: Stopping error criteria\n",
    "            learning_rate: Learning rate used for the algorithm. If None\n",
    "                calculates the best learning rate.\n",
    "            sources: If values are for sources of data points rather than\n",
    "                   individual points. In the format of an assignment array\n",
    "                   or dict.\n",
    "                   \n",
    "            IMPT: how do we retool this to take in graphs/polygons\n",
    "                - might consider actual call as well for text/annotations\n",
    "        \"\"\"\n",
    "        if sources is None:\n",
    "            sources = {i:np.array([i]) for i in range(len(self.X))}\n",
    "        elif not isinstance(sources, dict):\n",
    "            sources = {i:np.where(sources==i)[0] for i in set(sources)}\n",
    "        address = None\n",
    "        if self.directory is not None:\n",
    "            address = os.path.join(self.directory, 'weights')\n",
    "        if learning_rate is None:\n",
    "            try:\n",
    "                learning_rate = self.g_shap_lr\n",
    "            except AttributeError:\n",
    "                self.g_shap_lr = self._one_step_lr()\n",
    "                learning_rate = self.g_shap_lr\n",
    "        model = ShapNN(self.problem, batch_size=1, max_epochs=1,\n",
    "                     learning_rate=learning_rate, weight_decay=0.,\n",
    "                     validation_fraction=0, optimizer='sgd',\n",
    "                     address=address, hidden_units=self.hidden_units)\n",
    "        for iteration in range(iterations):\n",
    "            model.fit(np.zeros((0, self.X.shape[-1])), self.y)\n",
    "            if 10 * (iteration+1) / iterations % 1 == 0:\n",
    "                print('{} out of {} G-Shapley iterations'.format(\n",
    "                    iteration + 1, iterations))\n",
    "            marginal_contribs = np.zeros(len(sources.keys()))\n",
    "            model.fit(self.X, self.y, self.X_test, self.y_test, \n",
    "                      sources=sources, metric=self.metric, \n",
    "                      max_epochs=1, batch_size=1)\n",
    "            val_result = model.history['metrics']\n",
    "            marginal_contribs[1:] += val_result[0][1:]\n",
    "            marginal_contribs[1:] -= val_result[0][:-1]\n",
    "            individual_contribs = np.zeros(len(self.X))\n",
    "            for i, index in enumerate(model.history['idxs'][0]):\n",
    "                individual_contribs[sources[index]] += marginal_contribs[i]\n",
    "                individual_contribs[sources[index]] /= len(sources[index])\n",
    "            self.mem_g = np.concatenate(\n",
    "                [self.mem_g, np.reshape(individual_contribs, (1,-1))])\n",
    "            self.idxs_g = np.concatenate(\n",
    "                [self.idxs_g, np.reshape(model.history['idxs'][0], (1,-1))])\n",
    "    \n",
    "    def _calculate_loo_vals(self, sources=None, metric=None):\n",
    "        \"\"\"Calculated leave-one-out values for the given metric.\n",
    "        \n",
    "        Args:\n",
    "            metric: If None, it will use the objects default metric.\n",
    "            sources: If values are for sources of data points rather than\n",
    "                   individual points. In the format of an assignment array\n",
    "                   or dict.\n",
    "        \n",
    "        Returns:\n",
    "            Leave-one-out scores\n",
    "        \"\"\"\n",
    "        if sources is None:\n",
    "            sources = {i:np.array([i]) for i in range(len(self.X))}\n",
    "        elif not isinstance(sources, dict):\n",
    "            sources = {i:np.where(sources==i)[0] for i in set(sources)}\n",
    "        print('Starting LOO score calculations!')\n",
    "        if metric is None:\n",
    "            metric = self.metric \n",
    "        self.restart_model()\n",
    "        if self.sample_weight is None:\n",
    "            self.model.fit(self.X, self.y)\n",
    "        else:\n",
    "            self.model.fit(self.X, self.y,\n",
    "                          sample_weight=self.sample_weight)\n",
    "        baseline_value = self.value(self.model, metric=metric)\n",
    "        vals_loo = np.zeros(len(self.X))\n",
    "        for i in sources.keys():\n",
    "            X_batch = np.delete(self.X, sources[i], axis=0)\n",
    "            y_batch = np.delete(self.y, sources[i], axis=0)\n",
    "            if self.sample_weight is not None:\n",
    "                sw_batch = np.delete(self.sample_weight, sources[i], axis=0)\n",
    "            if self.sample_weight is None:\n",
    "                self.model.fit(X_batch, y_batch)\n",
    "            else:\n",
    "                self.model.fit(X_batch, y_batch, sample_weight=sw_batch)\n",
    "                \n",
    "            removed_value = self.value(self.model, metric=metric)\n",
    "            vals_loo[sources[i]] = (baseline_value - removed_value)\n",
    "            vals_loo[sources[i]] /= len(sources[i])\n",
    "        return vals_loo\n",
    "    \n",
    "    def _merge_parallel_results(self, key, max_samples=None):\n",
    "        \"\"\"Helper method for 'merge_results' method.\"\"\"\n",
    "        numbers = [name.split('.')[-2].split('_')[-1]\n",
    "                   for name in os.listdir(self.directory) \n",
    "                   if 'mem_{}'.format(key) in name]\n",
    "        mem  = np.zeros((0, self.X.shape[0]))\n",
    "        n_sources = len(self.X) if self.sources is None else len(self.sources)\n",
    "        idxs = np.zeros((0, n_sources), int)\n",
    "        vals = np.zeros(len(self.X))\n",
    "        counter = 0.\n",
    "        for number in numbers:\n",
    "            if max_samples is not None:\n",
    "                if counter > max_samples:\n",
    "                    break\n",
    "            samples_dir = os.path.join(\n",
    "                self.directory, \n",
    "                'mem_{}_{}.pkl'.format(key, number)\n",
    "            )\n",
    "            print(samples_dir)\n",
    "            dic = pkl.load(open(samples_dir, 'rb'))\n",
    "            if not len(dic['mem_{}'.format(key)]):\n",
    "                continue\n",
    "            mem = np.concatenate([mem, dic['mem_{}'.format(key)]])\n",
    "            idxs = np.concatenate([idxs, dic['idxs_{}'.format(key)]])\n",
    "            counter += len(dic['mem_{}'.format(key)])\n",
    "            vals *= (counter - len(dic['mem_{}'.format(key)])) / counter\n",
    "            vals += len(dic['mem_{}'.format(key)]) / counter * np.mean(mem, 0)\n",
    "            os.remove(samples_dir)\n",
    "        merged_dir = os.path.join(\n",
    "            self.directory, \n",
    "            'mem_{}_0000.pkl'.format(key)\n",
    "        )\n",
    "        pkl.dump({'mem_{}'.format(key): mem, 'idxs_{}'.format(key): idxs}, \n",
    "                 open(merged_dir, 'wb'))\n",
    "        return mem, idxs, vals\n",
    "            \n",
    "    def merge_results(self, max_samples=None):\n",
    "        \"\"\"Merge all the results from different runs.\n",
    "        \n",
    "        Returns:\n",
    "            combined marginals, sampled indexes and values calculated \n",
    "            using the two algorithms. (If applicable)\n",
    "        \"\"\"\n",
    "        tmc_results = self._merge_parallel_results('tmc', max_samples)\n",
    "        self.marginals_tmc, self.indexes_tmc, self.values_tmc = tmc_results\n",
    "        if self.model_family not in ['logistic', 'NN']:\n",
    "            return\n",
    "        g_results = self._merge_parallel_results('g', max_samples)\n",
    "        self.marginals_g, self.indexes_g, self.values_g = g_results\n",
    "    \n",
    "    def performance_plots(self, vals, name=None, \n",
    "                          num_plot_markers=20, sources=None):\n",
    "        \"\"\"Plots the effect of removing valuable points.\n",
    "        \n",
    "        Args:\n",
    "            vals: A list of different valuations of data points each\n",
    "                 in the format of an array in the same length of the data.\n",
    "            name: Name of the saved plot if not None.\n",
    "            num_plot_markers: number of points in each plot.\n",
    "            sources: If values are for sources of data points rather than\n",
    "                   individual points. In the format of an assignment array\n",
    "                   or dict.\n",
    "                   \n",
    "        Returns:\n",
    "            Plots showing the change in performance as points are removed\n",
    "            from most valuable to least.\n",
    "        \"\"\"\n",
    "        plt.rcParams['figure.figsize'] = 8,8\n",
    "        plt.rcParams['font.size'] = 25\n",
    "        plt.xlabel('Fraction of train data removed (%)')\n",
    "        plt.ylabel('Prediction accuracy (%)', fontsize=20)\n",
    "        if not isinstance(vals, list) and not isinstance(vals, tuple):\n",
    "            vals = [vals]\n",
    "        if sources is None:\n",
    "            sources = {i:np.array([i]) for i in range(len(self.X))}\n",
    "        elif not isinstance(sources, dict):\n",
    "            sources = {i:np.where(sources==i)[0] for i in set(sources)}\n",
    "        vals_sources = [np.array([np.sum(val[sources[i]]) \n",
    "                                  for i in range(len(sources.keys()))])\n",
    "                  for val in vals]\n",
    "        if len(sources.keys()) < num_plot_markers:\n",
    "            num_plot_markers = len(sources.keys()) - 1\n",
    "        plot_points = np.arange(\n",
    "            0, \n",
    "            max(len(sources.keys()) - 10, num_plot_markers),\n",
    "            max(len(sources.keys())//num_plot_markers, 1)\n",
    "        )\n",
    "        perfs = [self._portion_performance(\n",
    "            np.argsort(vals_source)[::-1], plot_points, sources=sources)\n",
    "                 for vals_source in vals_sources]\n",
    "        rnd = np.mean([self._portion_performance(\n",
    "            np.random.permutation(np.argsort(vals_sources[0])[::-1]),\n",
    "            plot_points, sources=sources) for _ in range(10)], 0)\n",
    "        plt.plot(plot_points/len(self.X) * 100, perfs[0] * 100, \n",
    "                 '-', lw=5, ms=10, color='b')\n",
    "        if len(vals)==3:\n",
    "            plt.plot(plot_points/len(self.X) * 100, perfs[1] * 100, \n",
    "                     '--', lw=5, ms=10, color='orange')\n",
    "            legends = ['TMC-Shapley ', 'G-Shapley ', 'LOO', 'Random']\n",
    "        elif len(vals)==2:\n",
    "            legends = ['TMC-Shapley ', 'LOO', 'Random']\n",
    "        else:\n",
    "            legends = ['TMC-Shapley ', 'Random']\n",
    "        plt.plot(plot_points/len(self.X) * 100, perfs[-1] * 100, \n",
    "                 '-.', lw=5, ms=10, color='g')\n",
    "        plt.plot(plot_points/len(self.X) * 100, rnd * 100, \n",
    "                 ':', lw=5, ms=10, color='r')    \n",
    "        plt.legend(legends)\n",
    "        if self.directory is not None and name is not None:\n",
    "            plt.savefig(os.path.join(\n",
    "                self.directory, 'plots', '{}.png'.format(name)),\n",
    "                        bbox_inches = 'tight')\n",
    "            plt.close()\n",
    "            \n",
    "    def _portion_performance(self, idxs, plot_points, sources=None):\n",
    "        \"\"\"Given a set of indexes, starts removing points from \n",
    "        the first elemnt and evaluates the new model after\n",
    "        removing each point.\"\"\"\n",
    "        if sources is None:\n",
    "            sources = {i:np.array([i]) for i in range(len(self.X))}\n",
    "        elif not isinstance(sources, dict):\n",
    "            sources = {i:np.where(sources==i)[0] for i in set(sources)}\n",
    "        scores = []\n",
    "        init_score = self.random_score\n",
    "        for i in range(len(plot_points), 0, -1):\n",
    "            keep_idxs = np.concatenate([sources[idx] for idx \n",
    "                                        in idxs[plot_points[i-1]:]], -1)\n",
    "            X_batch, y_batch = self.X[keep_idxs], self.y[keep_idxs]\n",
    "            if self.sample_weight is not None:\n",
    "                sample_weight_batch = self.sample_weight[keep_idxs]\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                if (self.is_regression \n",
    "                    or len(set(y_batch)) == len(set(self.y_test))):\n",
    "                    self.restart_model()\n",
    "                    if self.sample_weight is None:\n",
    "                        self.model.fit(X_batch, y_batch)\n",
    "                    else:\n",
    "                        self.model.fit(X_batch, y_batch,\n",
    "                                      sample_weight=sample_weight_batch)\n",
    "                    scores.append(self.value(\n",
    "                        self.model,\n",
    "                        metric=self.metric,\n",
    "                        X=self.X_heldout,\n",
    "                        y=self.y_heldout\n",
    "                    ))\n",
    "                else:\n",
    "                    scores.append(init_score)\n",
    "        return np.array(scores)#[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b34ac57",
   "metadata": {},
   "source": [
    "# ACTUALLY DOING SHIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d6bc7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "#from Shapley import ShapNN\n",
    "#from DShap import DShap\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "#from shap_utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c18380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem, model = 'classification', 'NN'\n",
    "hidden_units = [] # Empty list in the case of logistic regression.\n",
    "train_size = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "062efa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance using the whole training set = 0.75\n"
     ]
    }
   ],
   "source": [
    "d, difficulty = 50, 1\n",
    "num_classes = 2\n",
    "tol = 0.03\n",
    "target_accuracy = 0.7\n",
    "important_dims = 5\n",
    "clf = return_model(model, solver='adam', hidden_units=tuple(hidden_units))\n",
    "_param = 1.0\n",
    "for _ in range(100):\n",
    "    X_raw = np.random.multivariate_normal(mean=np.zeros(d), cov = np.eye(d), \n",
    "                                          size=train_size + 5000)\n",
    "    _, y_raw, _, _ = label_generator(\n",
    "        problem, X_raw, param = _param,  difficulty = difficulty, important=important_dims)\n",
    "    clf.fit(X_raw[:train_size], y_raw[:train_size])\n",
    "    test_acc = clf.score(X_raw[train_size:], y_raw[train_size:])\n",
    "    if test_acc > target_accuracy:\n",
    "        break\n",
    "    _param *= 1.1\n",
    "print('Performance using the whole training set = {0:.2f}'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c4a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ba4bf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.54526954,  0.07430885,  0.41541552, ..., -1.6434548 ,\n",
       "         1.48462207,  0.65582252],\n",
       "       [-0.49520437,  0.3476683 ,  0.28150639, ..., -0.69743077,\n",
       "         0.22988036, -1.46242371],\n",
       "       [ 1.00483466,  0.47227334, -0.57037243, ...,  0.20196827,\n",
       "        -1.13144759,  0.89016045],\n",
       "       ...,\n",
       "       [-1.41388593,  0.47287723, -0.26637547, ...,  1.33594438,\n",
       "        -0.44252503,  0.71759764],\n",
       "       [ 2.06023561,  0.34548203,  1.04465051, ...,  1.25971256,\n",
       "        -1.02080802,  0.10165586],\n",
       "       [ 0.17028475,  0.78035585, -0.33318055, ...,  0.67714326,\n",
       "         1.82251384,  0.80150012]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a30b6a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /dartfs-hpc/rc/home/d/f0036rd/.conda/envs/SHAPenv/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1efd725a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LOO score calculations!\n",
      "LOO values calculated!\n",
      "10 out of 100 TMC_Shapley iterations.\n",
      "20 out of 100 TMC_Shapley iterations.\n",
      "30 out of 100 TMC_Shapley iterations.\n",
      "40 out of 100 TMC_Shapley iterations.\n",
      "50 out of 100 TMC_Shapley iterations.\n",
      "60 out of 100 TMC_Shapley iterations.\n",
      "70 out of 100 TMC_Shapley iterations.\n",
      "80 out of 100 TMC_Shapley iterations.\n",
      "90 out of 100 TMC_Shapley iterations.\n",
      "100 out of 100 TMC_Shapley iterations.\n",
      "10 out of 100 TMC_Shapley iterations.\n",
      "20 out of 100 TMC_Shapley iterations.\n",
      "30 out of 100 TMC_Shapley iterations.\n",
      "40 out of 100 TMC_Shapley iterations.\n",
      "50 out of 100 TMC_Shapley iterations.\n",
      "60 out of 100 TMC_Shapley iterations.\n",
      "70 out of 100 TMC_Shapley iterations.\n",
      "80 out of 100 TMC_Shapley iterations.\n",
      "90 out of 100 TMC_Shapley iterations.\n",
      "100 out of 100 TMC_Shapley iterations.\n",
      "10 out of 100 TMC_Shapley iterations.\n",
      "20 out of 100 TMC_Shapley iterations.\n",
      "30 out of 100 TMC_Shapley iterations.\n",
      "40 out of 100 TMC_Shapley iterations.\n",
      "50 out of 100 TMC_Shapley iterations.\n",
      "60 out of 100 TMC_Shapley iterations.\n",
      "70 out of 100 TMC_Shapley iterations.\n",
      "80 out of 100 TMC_Shapley iterations.\n",
      "90 out of 100 TMC_Shapley iterations.\n",
      "100 out of 100 TMC_Shapley iterations.\n",
      "10 out of 100 TMC_Shapley iterations.\n",
      "20 out of 100 TMC_Shapley iterations.\n",
      "30 out of 100 TMC_Shapley iterations.\n",
      "40 out of 100 TMC_Shapley iterations.\n",
      "50 out of 100 TMC_Shapley iterations.\n",
      "60 out of 100 TMC_Shapley iterations.\n",
      "70 out of 100 TMC_Shapley iterations.\n",
      "80 out of 100 TMC_Shapley iterations.\n",
      "90 out of 100 TMC_Shapley iterations.\n",
      "100 out of 100 TMC_Shapley iterations.\n",
      "10 out of 100 TMC_Shapley iterations.\n",
      "20 out of 100 TMC_Shapley iterations.\n",
      "30 out of 100 TMC_Shapley iterations.\n",
      "40 out of 100 TMC_Shapley iterations.\n",
      "50 out of 100 TMC_Shapley iterations.\n",
      "60 out of 100 TMC_Shapley iterations.\n",
      "70 out of 100 TMC_Shapley iterations.\n",
      "80 out of 100 TMC_Shapley iterations.\n",
      "90 out of 100 TMC_Shapley iterations.\n",
      "100 out of 100 TMC_Shapley iterations.\n",
      "10 out of 100 TMC_Shapley iterations.\n",
      "20 out of 100 TMC_Shapley iterations.\n",
      "30 out of 100 TMC_Shapley iterations.\n",
      "40 out of 100 TMC_Shapley iterations.\n",
      "50 out of 100 TMC_Shapley iterations.\n",
      "60 out of 100 TMC_Shapley iterations.\n",
      "70 out of 100 TMC_Shapley iterations.\n",
      "80 out of 100 TMC_Shapley iterations.\n",
      "90 out of 100 TMC_Shapley iterations.\n",
      "100 out of 100 TMC_Shapley iterations.\n",
      "10 out of 100 TMC_Shapley iterations.\n",
      "20 out of 100 TMC_Shapley iterations.\n",
      "30 out of 100 TMC_Shapley iterations.\n",
      "40 out of 100 TMC_Shapley iterations.\n",
      "50 out of 100 TMC_Shapley iterations.\n",
      "60 out of 100 TMC_Shapley iterations.\n",
      "70 out of 100 TMC_Shapley iterations.\n",
      "80 out of 100 TMC_Shapley iterations.\n",
      "90 out of 100 TMC_Shapley iterations.\n",
      "100 out of 100 TMC_Shapley iterations.\n"
     ]
    }
   ],
   "source": [
    "X, y = X_raw[:train_size], y_raw[:train_size]\n",
    "X_test, y_test = X_raw[train_size:], y_raw[train_size:]\n",
    "model = 'logistic'\n",
    "problem = 'NN'\n",
    "num_test = 1000\n",
    "directory = './temp'\n",
    "dshap = DShap(X, y, X_test, y_test, num_test, \n",
    "              sources=None, \n",
    "              sample_weight=None,\n",
    "              model_family=model, \n",
    "              metric='accuracy',\n",
    "              overwrite=True,\n",
    "              directory=directory)\n",
    "dshap.run(100, 0.1, g_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41f8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO values calculated!\n",
      "WARNING:tensorflow:From /dartfs-hpc/rc/home/d/f0036rd/.conda/envs/SHAPenv/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 23:27:20.310547: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-07-07 23:27:20.383549: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2022-07-07 23:27:20.386095: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2397390000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 out of 100 G-Shapley iterations\n",
      "20 out of 100 G-Shapley iterations\n",
      "30 out of 100 G-Shapley iterations\n",
      "40 out of 100 G-Shapley iterations\n",
      "50 out of 100 G-Shapley iterations\n",
      "60 out of 100 G-Shapley iterations\n",
      "70 out of 100 G-Shapley iterations\n",
      "80 out of 100 G-Shapley iterations\n",
      "90 out of 100 G-Shapley iterations\n",
      "100 out of 100 G-Shapley iterations\n",
      "10 out of 100 TMC_Shapley iterations.\n",
      "20 out of 100 TMC_Shapley iterations.\n",
      "30 out of 100 TMC_Shapley iterations.\n",
      "40 out of 100 TMC_Shapley iterations.\n",
      "50 out of 100 TMC_Shapley iterations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X, y = X_raw[:100], y_raw[:100]\n",
    "X_test, y_test = X_raw[100:], y_raw[100:]\n",
    "model = 'NN'\n",
    "problem = 'classification'\n",
    "num_test = 1000\n",
    "directory = './temp'\n",
    "dshap = DShap(X, y, X_test, y_test, num_test, model_family=model, metric='accuracy',\n",
    "              directory=directory)\n",
    "dshap.run(100, 0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X_raw[:100], y_raw[:100]\n",
    "X_test, y_test = X_raw[100:], y_raw[100:]\n",
    "model = 'logistic'\n",
    "problem = 'classification'\n",
    "num_test = 1000\n",
    "directory = './temp'\n",
    "dshap = DShap(X, y, X_test, y_test, num_test, model_family=model, metric='accuracy',\n",
    "              directory=directory)\n",
    "dshap.run(100, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef386e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dshap.merge_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plots(dshap.marginals_tmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba8da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plots(dshap.marginals_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7da3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dshap.performance_plots([dshap.vals_tmc, dshap.vals_g, dshap.vals_loo], num_plot_markers=20,\n",
    "                       sources=dshap.sources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f37b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dshap.vals_tmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ebc932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e05a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab0823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SHAPenv",
   "language": "python",
   "name": "shapenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
